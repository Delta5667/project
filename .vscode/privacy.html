<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Privacy Concerns - AI & Mathematics</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@700&family=Roboto&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <header>
    <div class="logo">
      <i class="fas fa-brain"></i> AI & Mathematics
    </div>
    <nav>
      <a href="math.html">Home</a>
      <a href="impact.html">Impact</a>
      <a href="usages.html">Usages</a>
      <a href="privacy.html">Privacy</a>
      <a href="bias.html">Bias</a>
      <a href="about.html">About Us</a>
    </nav>
  </header>
  <main>
    <section>
      <h1><i class="fas fa-user-secret"></i> Privacy Concerns</h1>
      <ul>
        <li>AI-powered tutoring systems in education raise several important privacy concerns, especially when used to support personalized learning in mathematics. These systems often collect and analyze large amounts of student data—including performance metrics, behavioral patterns, and even keystroke dynamics—to tailor instruction and feedback. While this data-driven approach can enhance learning, it also introduces risks related to data security, consent, and misuse. According to the U.S. Department of Education, many AI models are not designed with educational privacy laws like FERPA (Family Educational Rights and Privacy Act) in mind, which means they may inadvertently expose sensitive student information1. For example, if a tutoring system stores data on external servers without proper encryption or access controls, it could be vulnerable to breaches or unauthorized access.

          Another concern is the lack of transparency in how student data is used and shared. AI systems may use student data to improve algorithms or train future models, often without clear disclosure to students, parents, or educators. This raises ethical questions about consent and data ownership. The Department of Education emphasizes that educational institutions must ensure that AI tools align with privacy regulations and that students' personal information is protected throughout the data lifecycle1. Additionally, the use of third-party vendors for AI services can complicate accountability, as schools may not have full control over how data is managed. These privacy risks are especially critical for vulnerable populations, such as students with disabilities or those from marginalized communities, who may be disproportionately affected by data misuse or profiling. Addressing these concerns requires robust privacy policies, transparent data practices, and ongoing oversight to ensure that AI enhances education without compromising student rights.
          
          </li>
      </ul>
    </section>
  </main>
  <footer>
    <div class="socials">
      <a href="#" title="Twitter"><i class="fab fa-twitter"></i></a>
      <a href="#" title="GitHub"><i class="fab fa-github"></i></a>
      <a href="#" title="Email"><i class="fas fa-envelope"></i></a>
    </div>
    &copy; 2025 AI & Mathematics Information Hub
  </footer>
</body>
</html>
