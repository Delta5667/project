<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Bias in AI - AI & Mathematics</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@700&family=Roboto&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <header>
    <div class="logo">
      <i class="fas fa-brain"></i> AI & Mathematics
    </div>
    <nav>
      <a href="../index.html">Back</a>
      <a href="math.html">Home</a>
      <a href="information.html">Information</a>
      <a href="about.html">About Us</a>
    </nav>
  </header>
  <main>
    <section>
      <h1><i class="fas fa-balance-scale"></i> One Usage of Artificial Intelligence</h1>
      <ul>
        <li>AI-powered intelligent tutoring systems (ITS) in mathematics education 
        work by simulating the guidance of a human tutor through adaptive technologies. 
        These systems analyze student input in real time—such as answers to math problems 
        or interaction patterns—and use machine learning algorithms to adjust the difficulty, 
        pacing, and type of instruction provided. For example, if a student struggles with 
        solving linear equations, the ITS may offer simpler problems, provide hints, or 
        switch to visual explanations. Some systems, like conversational AI tutors, 
        engage students in dialogue to clarify misunderstandings and reinforce concepts. 
        These platforms often include features like automated feedback, personalized learning 
        paths, and performance tracking, which help both students and teachers monitor progress 
        and identify areas needing improvement. The U.S. Department of Education highlights that 
        such systems can enhance learning by offering immediate, tailored feedback and supporting 
        students who may not have access to traditional tutoring.
        </li>
      </ul>
    </section>
    <section>
      <h1><i class="fas fa-balance-scale"></i> Potential Data/Security Issues</h1>
      <ul>
          <li>However, the use of AI in educational settings can introduce bias, 
          particularly affecting vulnerable populations such as students from 
          underrepresented racial or socioeconomic groups. Bias can emerge from the 
          data used to train AI models, which may underrepresent certain demographics, 
          leading to inaccurate assessments or recommendations. The U.S. Census Bureau 
          highlights that demographic models powered by AI/ML can amplify biases if not 
          properly managed, especially when sensitive attributes like race or ethnicity 
          are involved. </li>
          <li>Additionally, the National Institute of Standards and Technology 
          (NIST) emphasizes that AI bias is not solely a technical issue but also stems from 
          systemic and human factors, such as institutional practices and societal norms. 
          These biases can result in unequal educational outcomes, reinforcing existing 
          disparities. Therefore, ensuring transparency and fairness in AI systems—through 
          methods like Explainable AI (XAI)—is essential to protect vulnerable students and 
          promote equitable learning environments. AI-powered tutoring systems in 
          education raise several important privacy concerns, especially when used to
           support personalized learning in mathematics. These systems often collect 
           and analyze large amounts of student data—including performance metrics, 
           behavioral patterns, and even keystroke dynamics—to tailor instruction 
           and feedback. While this data-driven approach can enhance learning, it 
           also introduces risks related to data security, consent, and misuse. 
           According to the U.S. Department of Education, many AI models are not 
           designed with educational privacy laws like FERPA (Family Educational 
           Rights and Privacy Act) in mind, which means they may inadvertently 
           expose sensitive student information1. For example, if a tutoring 
           system stores data on external servers without proper encryption or 
           access controls, it could be vulnerable to breaches or unauthorized access.
          </li>
      </ul>
    </section>
    <section>
      <h1><i class="fas fa-balance-scale"></i> Positive and Negative Impact of AI on Mathematics Industry</h1>
      <ul>
        <li>One positive impact of AI in the mathematics industry is its ability to personalize
           learning through intelligent tutoring systems. These systems adapt to each student's
            learning pace and style, offering real-time feedback, targeted practice problems, 
            and step-by-step guidance. According to a systematic review published in the 
            International Electronic Journal of Mathematics Education, AI technologies such 
            as adaptive learning platforms and intelligent tutors have significantly improved 
            student engagement and comprehension by customizing instruction to individual needs. 
            These tools not only help students master complex mathematical concepts but also assist 
            teachers by automating grading and identifying learning gaps. This personalized approach 
            has been especially beneficial in large classrooms where one-on-one instruction is limited, 
            allowing for more equitable access to quality education.</li>

          <li>On the other hand, a negative impact of AI in the mathematics industry is 
          the risk of reinforcing existing educational inequalities due to algorithmic bias. 
          AI systems are often trained on historical data that may not represent all student 
          populations equally. As highlighted in a U.S. Census Bureau working paper, if these 
          systems are not carefully designed and monitored, they can perpetuate biases against 
          underrepresented or vulnerable groups, such as students from low-income backgrounds or 
          non-native English speakers 2. For example, an AI tutor might misinterpret a student's 
          problem-solving approach if it deviates from the patterns seen in the training data, 
          leading to incorrect feedback or lower performance assessments. This can discourage 
          students and widen achievement gaps. The report emphasizes the importance of using 
          Explainable AI (XAI) to make AI decisions transparent and accountable, ensuring that 
          these technologies support rather than hinder educational equity.</li>
      </ul>
    </section>
  </main>
  <footer>
    <div class="socials">
      <a href="#" title="Twitter"><i class="fab fa-twitter"></i></a>
      <a href="#" title="GitHub"><i class="fab fa-github"></i></a>
      <a href="#" title="Email"><i class="fas fa-envelope"></i></a>
    </div>
    &copy; 2025 AI & Mathematics Information Hub
  </footer>
</body>
</html>